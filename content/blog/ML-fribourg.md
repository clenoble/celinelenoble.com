+++
date = "2019-12-04"
description = "Talk at Machine Learning Fribourg Meetup"
title = "Fairness Awareness in ML models"
+++

 <div class="overview">

 Overview | <i class="fa fa-bookmark"></i>
 ---------|---
 48' watch| Meetup presentation: identify when and where bias can be introduced during ML process and how to minimize it 

 </div>

Below is a talk I gave during the [ML Fribourg meetup](https://www.meetup.com/Fri-ML/) on November 27th 2019, based on a 2017 paper by Brian d'Alessandro, Cathy O'Neil and Tom Lagatta entitled [Conscientious Classification: A Data Scientist's guide to Discrimination-Aware Classification](https://www.liebertpub.com/doi/abs/10.1089/big.2016.0048). 

{{< youtube M-e32EIGFIU >}}

The talk led to a fruitful discussion (not recorded) about the need for data normalization, the risk involved in augmenting the loss function with a fairness-regularizer, algorithm aversion, what incentives could companies have to introduce more fairness, the need for regulation and more.

You can download the slides [here](https://gitlab.com/fri-ml/meetups/tree/master/2019-11-27_fairness-awareness-in-ML-models). They include additional links and a summary of the topics raised during the discussion.